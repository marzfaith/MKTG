---
title: "Assignment 4"
author: "Marissa"
date: "2/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Chapter 12 Tidy Data Notes

#### 12.1.1 Prerequisites
```{r}
library(tidyverse)
```
### 12.2 Tidy Data
```{r}
# runs the tables
table1

table2

table3

table4a 

table4b 

```

Dataset Tidy:
Each variable must have its own column
Each observation must have its own row
Each value must have its own cell

```{r}
# Compute rate per 10,000
table1 %>% 
  mutate(rate = cases / population * 10000)

# Compute cases per year
table1 %>% 
  count(year, wt = cases)
```

## 12.2.1 Exercises
```{r}
#1 Using prose, describe how the variables and observations are organised in each of the sample tables.

#Columns are their own variables, meaning year only has year or country only has a country.
table1

# Combined columns, such as cases and population in the type column.
table2

# Rate is a combine column of separated by a /.
table3

# Contains the cases, with the the years separated into separate columns.
table4a 

# Contains the population.
table4b 

```

```{r}
#2 Compute the rate for table2, and table 4a+table 4b. 
  #1 Extract the bumber of TB case per country per year.
  #2 Extract the matching population per country per year.
  #3 Divide the cases by population and mulitply by 1000
  #4 Sore back in the appropraite place
# Which representation is easiest to work with? Which is hardest? Why?

#Table2
cases <- table2 %>%
  filter(type == "cases")
populations <- table2 %>%
  filter(type == "population")
merged <- cbind(cases, populations)
merged$rates= (cases$count / populations$count)*1000
merged

#Tables4
rates_99 <- (table4a$`1999` / table4b$`1999`)*1000
rates_00 <- (table4a$`2000`/ table4b$`2000`)*1000
new <- table4a['country']
new$rates_00 = rates_00
new$rates_99 = rates_99
new

#Table 4a and 4b were easier to work with, whereas Table 2 had to be separated and filter before doing any of the calculations.
```


### 12.3 Pivoting

#### 12.3.1 Longer
A common problem is a dataset where some of the column names are not names of variables, but values of a variable.

pivot_longer() makes wide tables narrower and longer
```{r}
table4a
# Changes 1999 to year and 2000 to cases
table4a %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")
```

```{r}
table4b
# Tidying table 4b by using pivot_longer
table4b %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "population")
```

```{r}
# Combines the tidied table4a and table4b
tidy4a <- table4a %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")
tidy4b <- table4b %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "population")
left_join(tidy4a, tidy4b)
```

#### 12.3.2 Wider
pivot_wider() is the opposite of pivot_longer(). You use it when an observation is scattered across multiple rows.

pivot_wider() makes long tables shorter and wider.
```{r}
table2
# separates type into two columns of case and population with the count as the values
table2 %>%
    pivot_wider(names_from = type, values_from = count)
```

## 12.3.3 Exercises
```{r}
#1 Why are pivot_longer and pivot_wider not perfectly symmetrical?
stocks <- tibble(
  year   = c(2015, 2015, 2016, 2016),
  half  = c(   1,    2,     1,    2),
  return = c(1.88, 0.59, 0.92, 0.17)
)
stocks %>% 
  pivot_wider(names_from = year, values_from = return) %>% 
  pivot_longer(`2015`:`2016`, names_to = "year", values_to = "return")
# Since the shape of the original tibble has changed and the orignal placement of columns and values. Pivot_wider() creates each year as it's own column instead of a double value column.
```

```{r}
#2 Why does this code fail?

#table4a %>% 
#  pivot_longer(c(1999, 2000), names_to = "year", values_to = "cases")

# Fails because we tried to use column names as integers
```

```{r}
#3 Why would happen if you widen this table? Why? How could you add a new column to uniquely identify each value?
people <- tribble(
  ~name,             ~names,  ~values,
  #-----------------|--------|------
  "Phillip Woods",   "age",       45,
  "Phillip Woods",   "height",   186,
  "Phillip Woods",   "age",       50,
  "Jessica Cordero", "age",       37,
  "Jessica Cordero", "height",   156
)
# Receive an error when trying to widen the table, due to the duplication of names. To avoid the error, I would create columns for age and one for height.
people %>%
  pivot_wider(names_from = names, values_from = values)

```

```{r}
#4 Tidy the simple tibble below. Do you need to make it wider or longer? What are the variables?
preg <- tribble(
  ~pregnant, ~male, ~female,
  "yes",     NA,    10,
  "no",      20,    12
)

preg%>%
  pivot_longer(c('male','female'), names_to="sex",values_to=)
```

### 12.4 Separating and Uniting

#### 12.4.1 Separate
separate() pulls apart one column into multiple columns, by splitting wherever a separator character appears.
```{r}
table3
# separates rate into cases and population at the forward slash
table3 %>% 
  separate(rate, into = c("cases", "population"))
# could also write as:
#table3 %>% 
  #separate(rate, into = c("cases", "population"), sep = "/")
```

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE)
```

```{r}
table3 %>% 
  separate(year, into = c("century", "year"), sep = 2)
```

#### 12.4.2 Unite
unite() is the inverse of separate(): it combines multiple columns into a single column
```{r}
table5 %>% 
  unite(new, century, year)
```

```{r}
table5 %>% 
  unite(new, century, year, sep = "")
```

## 12.4.3 Exercises
```{r}
#1 What do the extra and fill arguments do in separate()? Experiment with the various options for the following two toy datasets.

# The extra argument 'g'. The extra tells what to do if there are too many
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"), extra = "drop")

tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"), extra = "merge")

# The fill argument 'f'. The fill argument tells it what to do if there is something missing.
tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("one", "two", "three"))
```

```{r}
#2 Both unite() and separate() have a remove argument. What does it do? Why would you set it to FALSE?

#The remove argument removes/discards the columns used to either unite or separate. Setting it to FALSE, keeps the original columns.
```

```{r}
#3 Compare and contrast separate() and extract(). Why are there three variations of separation (position, separator, groups), but only one unite?

# Separate() splits a column into multiple columns.
# Extract() splits a column into multuple columns as well.
# Separate and Extract both start with a single column broken into several columns.
# Unite takes multiple columns converts it into a single column.
```

### 12.5 Missing Values
* Explicitly, i.e. flagged with NA.
* Implicitly, i.e. simply not present in the data.
```{r}
# Missing two values
stocks <- tibble(
  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr    = c(   1,    2,    3,    4,    2,    3,    4),
  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)
```

```{r}
stocks %>% 
  pivot_wider(names_from = year, values_from = return)
```

```{r}
stocks %>% 
  pivot_wider(names_from = year, values_from = return) %>% 
  pivot_longer(
    cols = c(`2015`, `2016`), 
    names_to = "year", 
    values_to = "return", 
    values_drop_na = TRUE
  )
```

```{r}
stocks %>% 
  complete(year, qtr)
```

```{r}
treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)
```

```{r}
# Fill takes a set of columns where you want missing values to be replaced by the most recent non-missing value (sometimes called last observation carried forward).
treatment %>% 
  fill(person)
```

## 12.5.1 Exercises
```{r}
#1 Compare and contrast fill arguments to pivot_wider() and complete().

treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)

# Carries Derrick Whitmore to fill in the NA in person
treatment %>% 
  fill(person)

# Creates an error there is missing data from the person column. Must do pivot_longer() as well to drop the NA values.

#pivot_wider(names_from = person, values_from = response)

# Finds unique values and creates several NA in person
treatment %>%
  complete(treatment, response)
```

```{r}
#2 What does the direction argument to fill() do?

# The direction tells it in which direction it should take the last data to fill in the blanks with.


treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)

# Carries Katherine Burke to fill in the NA
fill(treatment, person, .direction = "up")
```

### 12.6 Case Study
```{r}
who
```

```{r}
# Focus on the values that are present and create new colum names.
who1 <- who %>% 
  pivot_longer(
    cols = new_sp_m014:newrel_f65, 
    names_to = "key", 
    values_to = "cases", 
    values_drop_na = TRUE
  )
who1
```

```{r}
# Structure of the values
who1 %>% 
  count(key)
```
* First three letters of each column denote new or old cases of TB.
* Next two letters describe the type of TB:
  + rel = relapse
  + ep = extrapulmonary TB
  + sn = smear negative
  + sp = smear positive
* Sixth letter gives the sex of the patient. M = male; F = female
* Numbers represent the age:
  + 014 = 0 – 14 years old
  + 1524 = 15 – 24 years old
  + 2534 = 25 – 34 years old
  + 3544 = 35 – 44 years old
  + 4554 = 45 – 54 years old
  + 5564 = 55 – 64 years old
  + 65 = 65 or older

```{r}
# Fixes variable names that are inconsistent
who2 <- who1 %>% 
  mutate(names_from = stringr::str_replace(key, "newrel", "new_rel"))
who2
```

```{r}
# Separates at each underscore
who3 <- who2 %>% 
  separate(key, c("new", "type", "sexage"), sep = "_")

who3
```

```{r}
who3 %>% 
  count(new)
```

```{r}
# Drops columns
who4 <- who3 %>% 
  select(-new, -iso2, -iso3)
```

```{r}
# Separates sexage into sex and age
who5 <- who4 %>% 
  separate(sexage, c("sex", "age"), sep = 1)

who5
```

```{r}
# TIDY DATASET
who %>%
  pivot_longer(
    cols = new_sp_m014:newrel_f65, 
    names_to = "key", 
    values_to = "cases", 
    values_drop_na = TRUE
  ) %>% 
  mutate(
    key = stringr::str_replace(key, "newrel", "new_rel")
  ) %>%
  separate(key, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1)
```

## 12.6.1 Exercises
```{r}
#1 In this case study I set values_drop_na = TRUE just to make it easier to check that we had the correct values. Is this reasonable? Think about how missing values are represented in this dataset. Are there implicit missing values? What's the difference between an NA and 0?

# values_drop_na = TRUE may be reasonable depending on no cases of TB were represented. If there are no 0s in the dataset, then NA may represent no cases of TB. Therefore dropping the NA values skews the data. 0 is an integer while NA means a blank in the dataset.
```

```{r}
#2 What happens if you neglect the mutate() step?
#(mutate(names_from = stringr::str_replace(key, "newrel", "new_rel")))

# The mutate steps replaces the variable name with new_rel for consistency purposes and to avoid following errors. It allows for the separation at the '_' in the following step to avoid multiple columns.
```

```{r}
#3 I claimed that iso2 and iso3 were redundant with country. Confirm this claim.

select(who3, country, iso2, iso3) %>%
  distinct() %>%
  group_by(country) %>%
  filter(n() > 1)
```

```{r}
#4 For each country, year, and sex compute the total number of cases of TB.

who5 %>%
  group_by(country, year, sex) %>%
  summarise(cases = sum(cases))

```

### 12.7 Non-Tidy Data
Two main reasons to use other data structures:
Alternative representations may have substantial performance or space advantages.
Specialised fields have evolved their own conventions for storing data that may be quite different to the conventions of tidy data.



```{r}
library(nycflights13)
library(tidyverse)
```

# Notes: Chapter 5 Data Transformation
```{r}
nycflights13::flights
```
### 5.2 Filter rows with filter()
Allows to subset observations based on their values
First argument: name of data frame
Second argument +: expressions that filter the data frame
```{r}
filter(flights, month == 1, day == 1)
```
The arrow saves the results
```{r}
jan1 <- filter(flights, month == 1, day == 1)
```
The arrow and parentheses saves AND prints the results
```{r}
(dec25 <- filter(flights, month == 12, day == 25))
```

#### 5.2.1 Comparisons
R provides the standard suite: >, >=, <, <=, != (not equal), and == (equal)

#### 5.2.2 Logical Operators
```{r}
# Finds all flights departed in November or December
filter(flights, month == 11 | month == 12)
```

```{r}
# Shorthand for the code above
nov_dec <- filter(flights, month %in% c(11, 12))
```

```{r}
# Simplifed complicated subsetting by rem
filter(flights, !(arr_delay > 120 | dep_delay > 120))
filter(flights, arr_delay <= 120, dep_delay <= 120)
```

#### 5.2.3 Missing Values
NA represents an unknown value
```{r}
df <- tibble(x = c(1, NA, 3))
filter(df, x > 1)


#this showcases both the FALSE and NA values explicitly
filter(df, is.na(x) | x > 1)
```


## 5.2.4 Exercises
```{r}
# 1.1 Had an arrival delay of two or more hours
filter(flights, arr_delay >= 120)
```

```{r}
# 1.2 Flew to Houston (IAH to HOU)
filter(flights, origin == "IAH", dest == "HOU")
```

```{r}
# 1.3 Were operated by United, American, or Delta
filter(flights, carrier %in% c("UA","AA","DL"))
```

```{r}
# 1.4 Departed in Summer (July(7), August(8), September(9))
filter(flights, month %in% 7:9)
```

```{r}
# 1.5 Arrived more than 2 hours late, but didn't leave late
filter(flights, arr_delay > 120, dep_delay <= 0)
```

```{r}
# 1.6 Were delayed by at least an hour, but made up over 30 mins in flight
filter(flights, dep_delay >= 60, dep_delay - arr_delay > 30)
```

```{r}
# 1.7 Departed between midnight and 6am (inclusive)
filter(flights, dep_time >= 2400 | dep_time <= 600)
```

```{r}
# 2. Another usful dplyr filtering helper is between(). What does it do? Can you use it simplify the code needed to answer the previous challenge?

#The between() function finds the flights that occur between the variables, such as the summer months in problem 1.4. 
filter(flights, between(month, 7,9))
```

```{r}
#3 How many flights have a missing dep_time? What other variables are missing? What might these rows represent?

#The arrival time, depart time, air time, and depart delay are all missing. This could imply the flight had been cancelled.
filter(flights, is.na(dep_time))
```

```{r}
#4 Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE & NA not missing? Can you figure out the general rule?

NA ^ 0
# Equals 1 always

NA | TRUE
# True is always true

NA & FALSE
# False is always false

#NA * 0 is not equal to 0, because the NA represents infinity and is undefined.
```

### 5.3 Arrange Rows with Arrange()
Arrange() is similiar to filter(); but changes the order
```{r}
arrange(flights, year, month, day)
```

```{r}
#orders columns in descending order
arrange(flights, desc(dep_delay))
```

```{r}
#missing values are sorted at the end
df <- tibble(x = c(5, 2, NA))
arrange(df, x)

arrange(df, desc(x))
```

## 5.3.1 Exercises
```{r}
#1 How could you use arrange() to sort all missing values to the start?
arrange(flights, desc(is.na(dep_time)), dep_time)
```

```{r}
#2 Sort flights to find the most delayed flights. Find the flights that left earliest.

#most delayed
arrange(flights, desc(dep_delay))
```
```{r}
#left earliest
arrange(flights, dep_delay)
```

```{r}
#3 Sort flights to find the fastest(highest speed) flights.
arrange(flights, air_time)
```

```{r}
#4 Which flights travelled the farthest? Which travlled the shortest?

# travelled the farthest
arrange(flights, desc(distance))
```
```{r}
# travelled the shortest
arrange(flights, distance)
```

### 5.4 Select Columns with Select()
Select() allows you to zoom in on useful subset using operations based on the names of the variables

```{r}
select(flights, year, month, day)

select(flights, year:day)

select(flights, -(year:day))
```

* starts_with("abc"): matches names that begin with “abc”.

* ends_with("xyz"): matches names that end with “xyz”.

* contains("ijk"): matches names that contain “ijk”.

* matches("(.)\\1"): selects variables that match a regular expression. This one matches any variables that contain repeated characters. You’ll learn more about regular expressions in strings.

* num_range("x", 1:3): matches x1, x2 and x3.

```{r}
# renames the values
rename(flights, tail_num = tailnum)
```

```{r}
# moves to the start of the data
select(flights, time_hour, air_time, everything())
```

## 5.4.1 Exercises
```{r}
#1 Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.

select(flights, dep_time, dep_delay, arr_time, arr_delay)
```

```{r}
#2 What happens if you include the name of a variable multiple times in a select() call?

select(flights, year, month, month)

# it ignores the duplication and only incldues the variable once
```

```{r}
#3 What does the one_of() function do? Why might it be helpful in conjunction with this vector?

vars <- c("year", "month", "day", "dep_delay", "arr_delay")
select(flights, one_of(vars))

#this only works if vars is not a column name in the flights data
```

```{r}
#4 Does the result of running the following code surpise you? How do the select helpers deal wit case by default? How can you change that default?

select(flights, contains("TIME"))
# it is ingores case

select(flights, contains("TIME", ignore.case = FALSE))
# changes the default behavior
```

### 5.5 Add New Variables with Mutate()
Mutate(): Adds new columns that are functions of existing columns; adds columns to the end of your dataset
```{r}
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)
mutate(flights_sml,
  gain = dep_delay - arr_delay,
  speed = distance / air_time * 60
)
```

```{r}
# can refer to the columns that were just created
mutate(flights_sml,
  gain = dep_delay - arr_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
```

```{r}
# only want to keep the new variables, use the transmute()
transmute(flights,
  gain = dep_delay - arr_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
```

#### 5.5.1 Useful Creation Functions
* Arithmetic operators: +, -, *, /, ^
  + Arithmetic operators are also useful in conjunction with the aggregate functions 
  + Not affected by group_by()
* Modular arithmetic: %/% (integer division) and %% (remainder), where x == y * (x %/% y) + (x %% y)
  + Breaks integers into pieces
  + Not affected by group_by()
```{r}
# example
transmute(flights,
  dep_time,
  hour = dep_time %/% 100,
  minute = dep_time %% 100
)
```
* Logs: log(), log2(), log10().
  + log2(): easy to interpret
  + Not affected by group_by()
* Offsets: lead() and lag() allow you to refer to leading or lagging values
  + Respect the groupings of group_by()
* Cumulative and rolling aggregates: R provides functions for running sums, products, mins and maxes: cumsum(), cumprod(), cummin(), cummax(); and dplyr provides cummean() for cumulative means
  + Calculate the total within each group
* Logical comparisons, <, <=, >, >=, !=, and ==
  + Not affected by group_by()
* Ranking: there are a number of ranking functions, but you should start with min_rank()
  + Default gives smallest values; use desc(x) to give the largest values
  + Follow within in each group when used with group_by()
  
## 5.5.2 Exercises
```{r}
#1 Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they're not really continuous numbers. Convert them to a more convenient represenation of number of minutes since midnight.


#divide dep_time by 100 to get hours since midnight, then mulitply by 60 to get minutes. Get the remainder of the dep_time and add the reaminding minutes. The 1440 represents midnight by converting it to 0.
flights_times <- mutate(flights,dep_time_mins = (dep_time %/% 100 * 60 + dep_time %% 100) %% 1440,sched_dep_time_mins = (sched_dep_time %/% 100 * 60 + sched_dep_time %% 100) %% 1440
)
# view columns
select(
  flights_times, dep_time, dep_time_mins, sched_dep_time,
  sched_dep_time_mins
)
```

```{r}
#2 Compare air_time and arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it?

# I would think that air_time = arr_time-dep_time.
select(flights, air_time, arr_time, dep_time)

# The arr_time and dep_time need to be converted to minutes from midnight like #1 to get a true comparison.
```

```{r}
#3 Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?

# I would expect the dep_delay = dep_time - sched_dep_time
select(flights, dep_time, sched_dep_time, dep_delay)

# To get a true comparison, then the numbers would need to be converted to minutes from midnight. 
```

```{r}
#4 Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank().

flights %>%
  filter(min_rank(-(dep_delay)) %in% 1:10)
```

```{r}
#4 What does 1:3 + 1:10 return? Why?
1:3 + 1:10
# Returns a warning; could indicate a bug
```

```{r}
#6 What trignometric function does R provide?

#sin(), cos(), tan()
```

### 5.6 Grouped Summaries with Summarise()
```{r}
# Collapses data frame to a single row
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

```{r}
# Summarise() is more useful when paired with group_by()
by_day <- group_by (flights, year, month, day)
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
```
#### 5.6.1 Combining Mulitple Operations with the Pipe
```{r}
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest,
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count > 20, dest != "HNL")
```

```{r}
# Same problem using the pipe %>%
# Focuses on the transformations, not what's being transformed
delays <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")
```

#### 5.6.2 Missing Values
```{r}
# The na.rm produces a lot of missing values
flights %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))
```

```{r}
# Removes the missing values
flights %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay, na.rm = TRUE))
```

```{r}
# Takes into account of the cancelled flights
not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))
```

#### 5.6.3 Counts
Good idea to include: count(n()) or (sum(!is.na(x))) to avoid conclusions based on small amounts of data
```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay)
  )
```

```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )
```

#### 5.6.4 Useful Summary Functions
* Measures of location: mean(x), median(x)
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    avg_delay1 = mean(arr_delay),
    avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay
  )
```

* Measures of spread: sd(x), IQR(x), mad(x)
```{r}
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(distance_sd = sd(distance)) %>% 
  arrange(desc(distance_sd))
```

* Measures of rank: min(x), quantile(x, 0.25), max(x)
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first = min(dep_time),
    last = max(dep_time)
  )
```

* Measures of position: first(x), nth(x,2), last(x)
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first_dep = first(dep_time), 
    last_dep = last(dep_time)
  )
```

```{r}
# Complementary to measures of position
not_cancelled %>% 
  group_by(year, month, day) %>% 
  mutate(r = min_rank(desc(dep_time))) %>% 
  filter(r %in% range(r))
```

* Counts: n(), sum(!is.na(x)), n_distinct(x)
```{r}
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  arrange(desc(carriers))
```

```{r}
not_cancelled %>% 
  count(dest)
```

```{r}
# Total number of miles a plane flew
not_cancelled %>% 
  count(tailnum, wt = distance)
```

```{r}
# How many flights left before 5am? (these usually indicate delayed
# flights from the previous day)
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(n_early = sum(dep_time < 500))
```

```{r}
# What proportion of flights are delayed by more than an hour?
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(hour_prop = mean(arr_delay > 60))
```

#### 5.6.5 Grouping by Multiple Variables
```{r}
daily <- group_by(flights, year, month, day)
(per_day   <- summarise(daily, flights = n()))

(per_month <- summarise(per_day, flights = sum(flights)))

(per_year  <- summarise(per_month, flights = sum(flights)))
```

#### 5.6.6 Ungrouping
```{r}
daily %>% 
  ungroup() %>%             # no longer grouped by date
  summarise(flights = n())  # all flights
```

## 5.6.7 Exercises
```{r}
#1 Brainstorm at least 5 different ways to assess the typical dealy characteristics of a group of flights.
delay_char <-
  flights %>%
  group_by(flight) %>%
  summarise(n = n(),
            fif_early = mean(arr_delay == -15, na.rm = TRUE),
            fif_late = mean(arr_delay == 15, na.rm = TRUE),
            ten_always = mean(arr_delay == 10, na.rm = TRUE),
            thirty_early = mean(arr_delay == -30, na.rm = TRUE),
            thirty_late = mean(arr_delay == 30, na.rm = TRUE),
            per_on_time = mean(arr_delay == 0, na.rm = TRUE),
            two_hours = mean(arr_delay > 120, na.rm = TRUE))

#A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.

delay_char %>%
  filter(fif_early == 0.5, fif_late == 0.5)

#A flight is always 10 minutes late.

delay_char %>%
  filter(ten_always == 1)

#A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.

delay_char %>%
  filter(thirty_early == 0.5 & thirty_late == 0.5)

#99% of the time a flight is on time. 1% of the time it’s 2 hours late.

delay_char %>%
  filter(per_on_time == 0.99 & two_hours == 0.01)

# Which is more important: arrival delay or departure delay?
# Arrival delay is mort important because it can affect the following flights/connector flights. 
```

```{r}
#2 Come up with another approach that will give you the same output as not_cancelled %>% count(dest) and not_cancelled %>% count(tailnum, wt = distance) (without using count()).

not_cancelled %>% count(dest)

not_cancelled %>%
  group_by(dest) %>%
  summarise(n = length(dest))
```

```{r}
#3 Our defintion of cancelled flights (is.na(dep_delay)) | is.na(arr_delay)) is slightly suboptimal. Why? Which is the most important column?

#The most important column is the arr_delay. The definition is suboptimal because if a flight never left, then it was cancelled.
```

```{r}
#4 Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?
flights%>% 
  group_by(day) %>%
  summarise(cancelled = mean(is.na(dep_delay)))
# I'm not sure what the pattern is.
```

```{r}
#5 Which carrier has the worst delays? Challenge: Can you disentangle the effects of bad airports vs. bad carriers? Why/why not?
flights %>%
  group_by(carrier) %>%
  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(desc(arr_delay))

# I'm confused by the challenge question. F9 is the worst carrier. Would you look at the airports that it goes to?
```

```{r}
#6 What does the sort argument to count() do. When might you use it?

#Sorts the results in the order of 'n'; Sorts based on the count
```

### 5.7 Grouped Mutates (and Filters)
```{r}
flights_sml %>% 
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

```{r}
popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests
```

```{r}
popular_dests %>% 
  filter(arr_delay > 0) %>% 
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
  select(year:day, dest, arr_delay, prop_delay)
```

## 5.7.1 Exercises
```{r}
#1 Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping.

# See #### 5.5.1 Useful Creation Functions for notes
```

```{r}
#2 Which plane(tailnum) has the worst on-time record?

flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(tailnum) %>%
  summarise(prop_time = sum(arr_delay <= 30)/n(),
            mean_arr = mean(arr_delay, na.rm = T),
            fl = n()) %>%
  arrange(desc(prop_time))
```

```{r}
#3 What time of day should you fly if you want to avoid delays as much as possible?

# Grouped by hour to get the time of day
flights %>%
  group_by(hour) %>%
  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(arr_delay)
# Morning flights have less delays
```

```{r}
#4 For each destination, compute the total minutes of delay. For each flight, compute the proportion of the delay for its destination.
flights %>%
  group_by(dest) %>%
  filter(!is.na(dep_delay)) %>%
  summarise(total=sum(dep_delay))

flights%>%
  group_by(dest, tailnum)%>%
  filter(!is.na(dep_delay)) %>%
  summarise(avg=mean(dep_delay))
```

```{r}
#5 Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag(), explore how the delay of a flight is related to the delay of the immediately preceding flight.
flights%>%
  group_by(origin)%>%
  arrange(origin,month,day,dep_time)%>%
  mutate(dep_delay_lag = lag(dep_delay)) %>%
  filter(!is.na(dep_delay), !is.na(dep_delay_lag))
```

```{r}
#6 Look at each destination. Can you find flights that are suspiciously fast? Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?

flights %>%
  group_by(dest) %>%
  mutate(shortest = air_time - min(air_time, na.rm = TRUE)) %>%
  top_n(1, air_time) %>%
  arrange(desc(air_time)) %>%
  select(tailnum, sched_dep_time, sched_arr_time, shortest)
```

```{r}
#7 Find all the destinations that are flown by at least two carriers. Use that information to rank the carriers.

flights %>%
  group_by(dest) %>%
  filter(n_distinct(carrier) >= 2) %>%
  group_by(carrier) %>%
  summarise(n = n_distinct(dest)) %>%
  arrange(desc(n))
```

```{r}
#8 For each plan, count the number of flights before the first delay of greater than 1 hour.

flights %>%
   filter(!is.na(dep_delay)) %>%
   group_by(tailnum) %>%
   mutate(total = sum(dep_delay > 60))

```




